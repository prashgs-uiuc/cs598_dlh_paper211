{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1775,"status":"ok","timestamp":1650730134596,"user":{"displayName":"Prash S","userId":"14515616873443422507"},"user_tz":300},"id":"mAyreVGnVpS_","outputId":"29f463bc-7e25-4784-e93b-82c3b4bd9ff7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","import sys\n","\n","PATH = '/content/drive/MyDrive/Colab Notebooks/CS598_DLH_Paper211'\n","sys.path.append(PATH)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7RcfrnC6Vfp8"},"outputs":[],"source":["import pandas as pd\n","import os\n","import numpy as np\n","from gensim.models import Word2Vec, FastText\n","# import glove\n","# from glove import Corpus\n","\n","import collections\n","import gc\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n"]},{"cell_type":"code","source":["#!pip3 install pickle5\n","import pickle5 as pickle\n","with open(PATH + \"/data/ner_df.p\", \"rb\") as fh:\n","  new_notes = pickle.load(fh)"],"metadata":{"id":"96gKFCl9Ljmv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#new_notes = pd.read_pickle(PATH + \"/data/ner_df.p\")  # med7"],"metadata":{"id":"PF4prEehLlEx"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OEQMjYXgVfqK","executionInfo":{"status":"ok","timestamp":1650730302679,"user_tz":300,"elapsed":3951,"user":{"displayName":"Prash S","userId":"14515616873443422507"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3ce5653e-9a9f-4722-9674-849ed2bf9b6d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['SUBJECT_ID', 'HADM_ID_y', 'CHARTTIME', 'TEXT', 'preprocessed_text',\n","       'ner'],\n","      dtype='object')"]},"metadata":{},"execution_count":7}],"source":["\n","w2vec = Word2Vec.load(PATH + \"/embeddings/word2vec.model\")\n","w2vec = w2vec.wv\n","fasttext = FastText.load(PATH + \"/embeddings/FastText/fasttext.model\")\n","fasttext = fasttext.wv\n","new_notes.columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RVnjQnVJVfqN"},"outputs":[],"source":["null_index_list = []\n","for i in new_notes.itertuples():\n","    if len(i.ner) == 0:\n","        null_index_list.append(i.Index)\n","new_notes.drop(null_index_list, inplace=True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D1kSNFleVfqP"},"outputs":[],"source":["def mean(a):\n","    return sum(a) / len(a)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UngYGMuOVfqR"},"outputs":[],"source":["med7_ner_data = {}\n","\n","for ii in new_notes.itertuples():\n","\n","    p_id = ii.SUBJECT_ID\n","    ind = ii.Index\n","\n","    try:\n","        new_ner = new_notes.loc[ind].ner\n","    except:\n","        new_ner = []\n","\n","    unique = set()\n","    new_temp = []\n","\n","    for j in new_ner:\n","        for k in j:\n","\n","            unique.add(k[0])\n","            new_temp.append(k)\n","\n","    if p_id in med7_ner_data:\n","        for i in new_temp:\n","            med7_ner_data[p_id].append(i)\n","    else:\n","        med7_ner_data[p_id] = new_temp\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1650730348132,"user":{"displayName":"Prash S","userId":"14515616873443422507"},"user_tz":300},"id":"9ibC-wllVfqU","outputId":"8e5002da-adc9-4cc8-ca5a-49f5761b62a4"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[[('percocet', 'DRUG'), ('po', 'ROUTE'), ('tf :', 'FREQUENCY')]]"]},"metadata":{},"execution_count":11}],"source":["med7_ner_data[1106]\n","new_ner\n","# len(med7_ner_data[1106])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0yOnijnuVfqZ"},"outputs":[],"source":["pd.to_pickle(med7_ner_data, PATH + \"/data/new_ner_word_dict.pkl\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k6ic5Cj_Vfqc"},"outputs":[],"source":["# w2vec['at 9p , by 10:15- pt with runs']\n","# fasttext['q6h']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":537386,"status":"ok","timestamp":1650730900013,"user":{"displayName":"Prash S","userId":"14515616873443422507"},"user_tz":300},"id":"aoAYZKqdVfqk","outputId":"9c7c636e-8e93-4f57-eb00-fa3ed3be8889"},"outputs":[{"output_type":"stream","name":"stdout","text":["w2vec starting..\n","w2vec Done..\n","fasttext starting..\n","fasttext Done..\n","combined starting..\n","21731 21809 21837\n"]}],"source":["\n","data_types = [med7_ner_data]\n","data_names = [\"new_ner\"]\n","\n","for data, names in zip(data_types, data_names):\n","    new_word2vec = {}\n","    print(\"w2vec starting..\")\n","    for k,v in data.items():\n","\n","        patient_temp = []\n","        for i in v:\n","            try:\n","                patient_temp.append(w2vec[i[0]])\n","            except:\n","                avg = []\n","                num = 0\n","                temp = []\n","\n","                if len(i[0].split(\" \")) > 1:\n","                    for each_word in i[0].split(\" \"):\n","                        try:\n","                            temp = w2vec[each_word]\n","                            avg.append(temp)\n","                            num += 1\n","                        except:\n","                            pass\n","                    if num == 0: continue\n","                    avg = np.asarray(avg)\n","                    t = np.asarray(list(map(np.mean, zip(*avg))))\n","                    patient_temp.append(t)\n","        if len(patient_temp) == 0: \n","            continue\n","        new_word2vec[k] = patient_temp\n","    print(\"w2vec Done..\")\n","    #############################################################################\n","    print(\"fasttext starting..\")\n","        \n","    new_fasttextvec = {}\n","    for k,v in data.items():\n","        patient_temp = []\n","        for i in v:\n","            try:\n","                patient_temp.append(fasttext[i[0]])\n","            except:\n","                pass\n","        if len(patient_temp) == 0: \n","          continue\n","        new_fasttextvec[k] = patient_temp\n","    print(\"fasttext Done..\")\n","    #############################################################################    \n","        \n","    print(\"combined starting..\")\n","    new_concatvec = {}\n","\n","    for k,v in data.items():\n","        patient_temp = []\n","    #     if k != 6: continue\n","        for i in v:\n","            w2vec_temp = []\n","            try:\n","                w2vec_temp = w2vec[i[0]]\n","            except:\n","                avg = []\n","                num = 0\n","                temp = []\n","\n","                if len(i[0].split(\" \")) > 1:\n","                    for each_word in i[0].split(\" \"):\n","                        try:\n","                            temp = w2vec[each_word]\n","                            avg.append(temp)\n","                            num += 1\n","                        except:\n","                            pass\n","                    if avg:\n","                        avg = np.asarray(avg)\n","                        w2vec_temp = np.asarray(list(map(np.mean, zip(*avg))))\n","                    else: \n","                        w2vec_temp = [0] * 100\n","                else:\n","                    w2vec_temp = [0] * 100\n","\n","            try:\n","                fasttemp = fasttext[i[0]]\n","            except:\n","                fasttemp = [0] * 100\n","\n","            appended = np.append(fasttemp, w2vec_temp, 0)\n","\n","            patient_temp.append(appended)\n","        if len(patient_temp) == 0: continue\n","        new_concatvec[k] = patient_temp\n","\n","    print(len(new_word2vec), len(new_fasttextvec), len(new_concatvec))\n","    pd.to_pickle(new_word2vec, PATH + \"/data/\"+names+\"_word2vec_dict.pkl\")\n","    pd.to_pickle(new_fasttextvec, PATH + \"/data/\"+names+\"_fasttext_dict.pkl\")\n","    pd.to_pickle(new_concatvec, PATH + \"/data/\"+names+\"_combined_dict.pkl\")"]},{"cell_type":"code","source":["diff = set(new_fasttextvec.keys()).difference(set(new_word2vec))\n","print(diff)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ok4yST_9LPcO","executionInfo":{"status":"ok","timestamp":1650731166779,"user_tz":300,"elapsed":219,"user":{"displayName":"Prash S","userId":"14515616873443422507"}},"outputId":"ca19f8d1-74bd-4a35-f435-ededac529b7d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{90628, 91652, 97803, 74260, 41494, 9751, 91672, 95770, 73770, 94256, 68663, 86589, 80464, 58452, 45657, 84063, 79461, 96361, 44652, 63113, 51361, 86694, 18601, 4268, 55987, 67256, 41163, 55503, 83151, 66775, 70871, 9449, 55017, 92907, 14581, 66295, 45816, 95995, 67323, 89854, 48910, 98574, 26387, 76058, 69407, 56100, 81194, 10028, 41783, 90430, 78143, 77128, 44369, 68435, 59231, 46439, 57199, 95603, 41844, 63354, 93565, 83838, 50561, 6541, 83856, 82339, 65956, 90539, 92610, 83398, 85968, 85457, 73684, 44511, 55267, 53228, 85997, 79858}\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":45772,"status":"ok","timestamp":1650731223807,"user":{"displayName":"Prash S","userId":"14515616873443422507"},"user_tz":300},"id":"ngnkVptDVfqs","outputId":"7827a9c0-db8f-4640-f121-ec0324198e4b"},"outputs":[{"output_type":"stream","name":"stdout","text":["21731 21731 21759\n"]}],"source":["\n","for i in diff:\n","    del new_fasttextvec[i]\n","    del new_concatvec[i]\n","print(len(new_word2vec), len(new_fasttextvec), len(new_concatvec))\n","\n","\n","pd.to_pickle(new_word2vec, PATH + \"/data/\"+\"new_ner\"+\"_word2vec_limited_dict.pkl\")\n","pd.to_pickle(new_fasttextvec, PATH + \"/data/\"+\"new_ner\"+\"_fasttext_limited_dict.pkl\")\n","pd.to_pickle(new_concatvec, PATH + \"/data/\"+\"new_ner\"+\"_combined_limited_dict.pkl\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i5qK6d4RVfqv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650731228397,"user_tz":300,"elapsed":141,"user":{"displayName":"Prash S","userId":"14515616873443422507"}},"outputId":"f02d9793-bac9-43fc-94a0-949e1617d7ce"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["21731"]},"metadata":{},"execution_count":17}],"source":["len(new_fasttextvec)"]},{"cell_type":"code","source":[""],"metadata":{"id":"9OcgDUWT2lVZ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","name":"05-Represent-Entities-With-Different-Embeddings.ipynb","provenance":[]},"interpreter":{"hash":"9914b233ec2e25a614166f3945d69cc76d431b9f068beee7e414494da19aa985"},"kernelspec":{"display_name":"Python 2","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}