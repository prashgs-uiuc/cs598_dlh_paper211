{"cells":[{"cell_type":"code","source":["#! pip install 'h5py==2.10.0' --force-reinstall"],"metadata":{"id":"WqUDERnpTfr2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%tensorflow_version 1.x\n","\n","from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","\n","import sys\n","\n","PATH = '/content/drive/MyDrive/Colab Notebooks/CS598_DLH_Paper211'\n","sys.path.append(PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OIcHaw_cYr4m","executionInfo":{"status":"ok","timestamp":1650735022180,"user_tz":300,"elapsed":22868,"user":{"displayName":"Prash S","userId":"14515616873443422507"}},"outputId":"838da165-b2c4-449f-8054-b9338e2a8ee1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TensorFlow 1.x selected.\n","Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kg5a8-DpYFGr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650735027165,"user_tz":300,"elapsed":4996,"user":{"displayName":"Prash S","userId":"14515616873443422507"}},"outputId":"d006d792-6ac3-41b5-ca76-ecc8c6096d81"},"outputs":[{"output_type":"stream","name":"stderr","text":["Using TensorFlow backend.\n"]}],"source":["import pandas as pd\n","import os\n","import numpy as np\n","from gensim.models import Word2Vec, FastText\n","# import glove\n","# from glove import Corpus\n","\n","import collections\n","import gc \n","\n","import keras\n","from keras import backend as K\n","from keras import regularizers\n","from keras.models import Sequential, Model\n","from keras.layers import Flatten, Dense, Dropout, Input, concatenate, merge, Activation, Concatenate, LSTM, GRU\n","from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, BatchNormalization, GRU, Convolution1D, LSTM\n","from keras.layers import UpSampling1D, MaxPooling1D, GlobalMaxPooling1D, GlobalAveragePooling1D,MaxPool1D, merge\n","\n","from keras.optimizers import Adam\n","\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, History, ReduceLROnPlateau\n","from keras.utils import np_utils\n","from keras.backend.tensorflow_backend import set_session, clear_session, get_session\n","import tensorflow as tf\n","\n","\n","from sklearn.utils import class_weight\n","from sklearn.metrics import average_precision_score, roc_auc_score, accuracy_score, f1_score\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kSZQM9hKYFGw"},"outputs":[],"source":["def create_dataset(dict_of_ner):\n","    temp_data = []\n","    for k, v in sorted(dict_of_ner.items()):\n","        temp = []\n","        for embed in v:\n","            temp.append(embed)\n","        temp_data.append(np.mean(temp, axis = 0)) \n","    return np.asarray(temp_data)\n","\n","def make_prediction_multi_avg(model, test_data):\n","    probs = model.predict(test_data)\n","    y_pred = [1 if i>=0.5 else 0 for i in probs]\n","    return probs, y_pred\n","\n","def save_scores_multi_avg(predictions, probs, ground_truth, \n","                          \n","                          embed_name, problem_type, iteration, hidden_unit_size,\n","                          \n","                          sequence_name, type_of_ner):\n","    \n","    auc = roc_auc_score(ground_truth, probs)\n","    auprc = average_precision_score(ground_truth, probs)\n","    acc   = accuracy_score(ground_truth, predictions)\n","    F1    = f1_score(ground_truth, predictions)\n","    \n","    result_dict = {}    \n","    result_dict['auc'] = auc\n","    result_dict['auprc'] = auprc\n","    result_dict['acc'] = acc\n","    result_dict['F1'] = F1\n","    \n","    result_path = PATH + \"/results/proposed/\"\n","    file_name = str(sequence_name)+\"-\"+str(hidden_unit_size)+\"-\"+embed_name\n","    file_name = file_name +\"-\"+problem_type+\"-\"+str(iteration)+\"-\"+type_of_ner+\"-avg-.p\"\n","    pd.to_pickle(result_dict, os.path.join(result_path, file_name))\n","\n","    print(f'auc-{auc}, auprc-{auprc}, acc-{acc}, f1-{F1}')\n","    \n","def avg_ner_model(layer_name, number_of_unit, embedding_name):\n","\n","    print(f'Inputs-{layer_name}, {number_of_unit}, {embedding_name}')\n","    if embedding_name == \"concat\":\n","        input_dimension = 200\n","    else:\n","        input_dimension = 100\n","\n","    sequence_input = Input(shape=(24,104))\n","\n","    input_avg = Input(shape=(input_dimension, ), name = \"avg\")        \n","#     x_1 = Dense(256, activation='relu')(input_avg)\n","#     x_1 = Dropout(0.3)(x_1)\n","    \n","    if layer_name == \"GRU\":\n","        x = GRU(number_of_unit)(sequence_input)\n","    elif layer_name == \"LSTM\":\n","        x = LSTM(number_of_unit)(sequence_input)\n","\n","    x = keras.layers.Concatenate()([x, input_avg])\n","\n","    x = Dense(256, activation='relu')(x)\n","    x = Dropout(0.2)(x)\n","    \n","    \n","    logits_regularizer = tf.contrib.layers.l2_regularizer(scale=0.01)\n","    \n","    preds = Dense(1, activation='sigmoid',use_bias=False, kernel_regularizer=logits_regularizer)(x)\n","    \n","    \n","    opt = Adam(lr=0.001, decay = 0.01)\n","    model = Model(inputs=[sequence_input, input_avg], outputs=preds)\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer=opt,\n","                  metrics=['acc'])\n","    \n","    return model"]},{"cell_type":"code","source":["# Reset Keras Session\n","def reset_keras(model):\n","    sess = get_session()\n","    clear_session()\n","    sess.close()\n","    sess = get_session()\n","\n","    try:\n","        del model # this is from global space - change this as you need\n","    except:\n","        pass\n","\n","    gc.collect() # if it's done something you should see a number being outputted"],"metadata":{"id":"SxY0ErsuVnbw"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MDMFcKbIYFGx"},"outputs":[],"source":["type_of_ner = \"new\"\n","\n","x_train_lstm = pd.read_pickle(PATH + \"/data/\"+type_of_ner+\"_x_train.pkl\")\n","x_dev_lstm = pd.read_pickle(PATH + \"/data/\"+type_of_ner+\"_x_dev.pkl\")\n","x_test_lstm = pd.read_pickle(PATH + \"/data/\"+type_of_ner+\"_x_test.pkl\")\n","\n","y_train = pd.read_pickle(PATH + \"/data/\"+type_of_ner+\"_y_train.pkl\")\n","y_dev = pd.read_pickle(PATH + \"/data/\"+type_of_ner+\"_y_dev.pkl\")\n","y_test = pd.read_pickle(PATH + \"/data/\"+type_of_ner+\"_y_test.pkl\")\n","\n","ner_word2vec = pd.read_pickle(PATH + \"/data/\"+type_of_ner+\"_ner_word2vec_limited_dict.pkl\")\n","ner_fasttext = pd.read_pickle(PATH + \"/data/\"+type_of_ner+\"_ner_fasttext_limited_dict.pkl\")\n","ner_concat = pd.read_pickle(PATH + \"/data/\"+type_of_ner+\"_ner_combined_limited_dict.pkl\")\n","\n","train_ids = pd.read_pickle(PATH + \"/data/\"+type_of_ner+\"_train_ids.pkl\")\n","dev_ids = pd.read_pickle(PATH + \"/data/\"+type_of_ner+\"_dev_ids.pkl\")\n","test_ids = pd.read_pickle(PATH + \"/data/\"+type_of_ner+\"_test_ids.pkl\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wkGFcO93YFGz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650736568686,"user_tz":300,"elapsed":1456185,"user":{"displayName":"Prash S","userId":"14515616873443422507"}},"outputId":"32b650ba-2e0c-4d8e-b501-fdd300f70ac7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Layer:  GRU\n","Hidden unit:  128\n","Embedding:  word2vec\n","=============================\n","Iteration number:  1\n","Problem type:  mort_hosp\n","__________________\n","Inputs-GRU, 128, word2vec\n","15219\n","WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 7s 438us/step - loss: 0.2841 - acc: 0.9020 - val_loss: 0.2390 - val_acc: 0.9122\n","\n","Epoch 00001: val_loss improved from inf to 0.23898, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 344us/step - loss: 0.2455 - acc: 0.9141 - val_loss: 0.2381 - val_acc: 0.9131\n","\n","Epoch 00002: val_loss improved from 0.23898 to 0.23806, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 343us/step - loss: 0.2300 - acc: 0.9173 - val_loss: 0.2338 - val_acc: 0.9145\n","\n","Epoch 00003: val_loss improved from 0.23806 to 0.23378, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 341us/step - loss: 0.2222 - acc: 0.9194 - val_loss: 0.2378 - val_acc: 0.9117\n","\n","Epoch 00004: val_loss did not improve from 0.23378\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.2167 - acc: 0.9212 - val_loss: 0.2344 - val_acc: 0.9131\n","\n","Epoch 00005: val_loss did not improve from 0.23378\n","Epoch 6/100\n","15219/15219 [==============================] - 6s 364us/step - loss: 0.2131 - acc: 0.9222 - val_loss: 0.2344 - val_acc: 0.9117\n","\n","Epoch 00006: val_loss did not improve from 0.23378\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.2098 - acc: 0.9238 - val_loss: 0.2335 - val_acc: 0.9117\n","\n","Epoch 00007: val_loss improved from 0.23378 to 0.23349, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 349us/step - loss: 0.2056 - acc: 0.9258 - val_loss: 0.2341 - val_acc: 0.9131\n","\n","Epoch 00008: val_loss did not improve from 0.23349\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 355us/step - loss: 0.2031 - acc: 0.9256 - val_loss: 0.2349 - val_acc: 0.9136\n","\n","Epoch 00009: val_loss did not improve from 0.23349\n","Epoch 10/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.2007 - acc: 0.9271 - val_loss: 0.2341 - val_acc: 0.9140\n","\n","Epoch 00010: val_loss did not improve from 0.23349\n","Epoch 11/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.1982 - acc: 0.9287 - val_loss: 0.2363 - val_acc: 0.9145\n","\n","Epoch 00011: val_loss did not improve from 0.23349\n","Epoch 12/100\n","15219/15219 [==============================] - 5s 342us/step - loss: 0.1963 - acc: 0.9283 - val_loss: 0.2351 - val_acc: 0.9122\n","\n","Epoch 00012: val_loss did not improve from 0.23349\n","auc-0.8806563353599437, auprc-0.5800385277631671, acc-0.9158233670653174, f1-0.47714285714285715\n","Problem type:  mort_icu\n","__________________\n","Inputs-GRU, 128, word2vec\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 370us/step - loss: 0.2217 - acc: 0.9307 - val_loss: 0.1748 - val_acc: 0.9390\n","\n","Epoch 00001: val_loss improved from inf to 0.17477, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.1783 - acc: 0.9405 - val_loss: 0.1767 - val_acc: 0.9390\n","\n","Epoch 00002: val_loss did not improve from 0.17477\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 348us/step - loss: 0.1677 - acc: 0.9446 - val_loss: 0.1725 - val_acc: 0.9418\n","\n","Epoch 00003: val_loss improved from 0.17477 to 0.17249, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.1605 - acc: 0.9480 - val_loss: 0.1717 - val_acc: 0.9418\n","\n","Epoch 00004: val_loss improved from 0.17249 to 0.17168, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.1544 - acc: 0.9480 - val_loss: 0.1720 - val_acc: 0.9395\n","\n","Epoch 00005: val_loss did not improve from 0.17168\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 346us/step - loss: 0.1498 - acc: 0.9500 - val_loss: 0.1726 - val_acc: 0.9404\n","\n","Epoch 00006: val_loss did not improve from 0.17168\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 344us/step - loss: 0.1465 - acc: 0.9500 - val_loss: 0.1710 - val_acc: 0.9385\n","\n","Epoch 00007: val_loss improved from 0.17168 to 0.17100, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 348us/step - loss: 0.1429 - acc: 0.9531 - val_loss: 0.1711 - val_acc: 0.9390\n","\n","Epoch 00008: val_loss did not improve from 0.17100\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 348us/step - loss: 0.1405 - acc: 0.9522 - val_loss: 0.1723 - val_acc: 0.9399\n","\n","Epoch 00009: val_loss did not improve from 0.17100\n","Epoch 10/100\n","15219/15219 [==============================] - 6s 368us/step - loss: 0.1379 - acc: 0.9540 - val_loss: 0.1716 - val_acc: 0.9399\n","\n","Epoch 00010: val_loss did not improve from 0.17100\n","Epoch 11/100\n","15219/15219 [==============================] - 6s 361us/step - loss: 0.1358 - acc: 0.9540 - val_loss: 0.1729 - val_acc: 0.9395\n","\n","Epoch 00011: val_loss did not improve from 0.17100\n","Epoch 12/100\n","15219/15219 [==============================] - 5s 346us/step - loss: 0.1321 - acc: 0.9543 - val_loss: 0.1729 - val_acc: 0.9413\n","\n","Epoch 00012: val_loss did not improve from 0.17100\n","auc-0.8870772664138458, auprc-0.5274734826988475, acc-0.9411223551057958, f1-0.4576271186440678\n","Problem type:  los_3\n","__________________\n","Inputs-GRU, 128, word2vec\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 373us/step - loss: 0.5873 - acc: 0.7179 - val_loss: 0.5444 - val_acc: 0.7431\n","\n","Epoch 00001: val_loss improved from inf to 0.54435, saving model to avg-word2vec-los_3-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 359us/step - loss: 0.5402 - acc: 0.7469 - val_loss: 0.5458 - val_acc: 0.7449\n","\n","Epoch 00002: val_loss did not improve from 0.54435\n","Epoch 3/100\n","15219/15219 [==============================] - 6s 376us/step - loss: 0.5287 - acc: 0.7468 - val_loss: 0.5382 - val_acc: 0.7472\n","\n","Epoch 00003: val_loss improved from 0.54435 to 0.53818, saving model to avg-word2vec-los_3-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 6s 376us/step - loss: 0.5236 - acc: 0.7529 - val_loss: 0.5365 - val_acc: 0.7505\n","\n","Epoch 00004: val_loss improved from 0.53818 to 0.53654, saving model to avg-word2vec-los_3-best_model.hdf5\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.5170 - acc: 0.7564 - val_loss: 0.5363 - val_acc: 0.7486\n","\n","Epoch 00005: val_loss improved from 0.53654 to 0.53629, saving model to avg-word2vec-los_3-best_model.hdf5\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.5125 - acc: 0.7554 - val_loss: 0.5366 - val_acc: 0.7505\n","\n","Epoch 00006: val_loss did not improve from 0.53629\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.5074 - acc: 0.7597 - val_loss: 0.5356 - val_acc: 0.7518\n","\n","Epoch 00007: val_loss improved from 0.53629 to 0.53564, saving model to avg-word2vec-los_3-best_model.hdf5\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.5052 - acc: 0.7631 - val_loss: 0.5375 - val_acc: 0.7458\n","\n","Epoch 00008: val_loss did not improve from 0.53564\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.5025 - acc: 0.7652 - val_loss: 0.5358 - val_acc: 0.7537\n","\n","Epoch 00009: val_loss did not improve from 0.53564\n","Epoch 10/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.4991 - acc: 0.7640 - val_loss: 0.5362 - val_acc: 0.7472\n","\n","Epoch 00010: val_loss did not improve from 0.53564\n","Epoch 11/100\n","15219/15219 [==============================] - 5s 355us/step - loss: 0.4961 - acc: 0.7692 - val_loss: 0.5365 - val_acc: 0.7454\n","\n","Epoch 00011: val_loss did not improve from 0.53564\n","Epoch 12/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.4943 - acc: 0.7673 - val_loss: 0.5358 - val_acc: 0.7505\n","\n","Epoch 00012: val_loss did not improve from 0.53564\n","auc-0.7110870543418889, auprc-0.49437244618830667, acc-0.7488500459981601, f1-0.3673232908458864\n","Problem type:  los_7\n","__________________\n","Inputs-GRU, 128, word2vec\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 381us/step - loss: 0.2974 - acc: 0.9109 - val_loss: 0.2661 - val_acc: 0.9228\n","\n","Epoch 00001: val_loss improved from inf to 0.26607, saving model to avg-word2vec-los_7-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.2578 - acc: 0.9205 - val_loss: 0.2631 - val_acc: 0.9238\n","\n","Epoch 00002: val_loss improved from 0.26607 to 0.26314, saving model to avg-word2vec-los_7-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.2500 - acc: 0.9212 - val_loss: 0.2622 - val_acc: 0.9214\n","\n","Epoch 00003: val_loss improved from 0.26314 to 0.26225, saving model to avg-word2vec-los_7-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.2442 - acc: 0.9218 - val_loss: 0.2627 - val_acc: 0.9242\n","\n","Epoch 00004: val_loss did not improve from 0.26225\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.2401 - acc: 0.9221 - val_loss: 0.2622 - val_acc: 0.9247\n","\n","Epoch 00005: val_loss improved from 0.26225 to 0.26224, saving model to avg-word2vec-los_7-best_model.hdf5\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.2362 - acc: 0.9227 - val_loss: 0.2620 - val_acc: 0.9242\n","\n","Epoch 00006: val_loss improved from 0.26224 to 0.26201, saving model to avg-word2vec-los_7-best_model.hdf5\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 355us/step - loss: 0.2359 - acc: 0.9229 - val_loss: 0.2627 - val_acc: 0.9228\n","\n","Epoch 00007: val_loss did not improve from 0.26201\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.2337 - acc: 0.9236 - val_loss: 0.2626 - val_acc: 0.9233\n","\n","Epoch 00008: val_loss did not improve from 0.26201\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.2308 - acc: 0.9223 - val_loss: 0.2625 - val_acc: 0.9228\n","\n","Epoch 00009: val_loss did not improve from 0.26201\n","Epoch 10/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.2299 - acc: 0.9229 - val_loss: 0.2636 - val_acc: 0.9228\n","\n","Epoch 00010: val_loss did not improve from 0.26201\n","Epoch 11/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.2278 - acc: 0.9231 - val_loss: 0.2631 - val_acc: 0.9228\n","\n","Epoch 00011: val_loss did not improve from 0.26201\n","auc-0.7266724460156269, auprc-0.21281031990577862, acc-0.9178932842686293, f1-0.027247956403269755\n","Embedding:  fasttext\n","=============================\n","Iteration number:  1\n","Problem type:  mort_hosp\n","__________________\n","Inputs-GRU, 128, fasttext\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 377us/step - loss: 0.2921 - acc: 0.8994 - val_loss: 0.2420 - val_acc: 0.9140\n","\n","Epoch 00001: val_loss improved from inf to 0.24204, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 356us/step - loss: 0.2439 - acc: 0.9144 - val_loss: 0.2364 - val_acc: 0.9164\n","\n","Epoch 00002: val_loss improved from 0.24204 to 0.23641, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.2291 - acc: 0.9188 - val_loss: 0.2356 - val_acc: 0.9136\n","\n","Epoch 00003: val_loss improved from 0.23641 to 0.23559, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 359us/step - loss: 0.2208 - acc: 0.9211 - val_loss: 0.2335 - val_acc: 0.9136\n","\n","Epoch 00004: val_loss improved from 0.23559 to 0.23348, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.2147 - acc: 0.9229 - val_loss: 0.2352 - val_acc: 0.9136\n","\n","Epoch 00005: val_loss did not improve from 0.23348\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 349us/step - loss: 0.2074 - acc: 0.9248 - val_loss: 0.2335 - val_acc: 0.9140\n","\n","Epoch 00006: val_loss did not improve from 0.23348\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.2035 - acc: 0.9265 - val_loss: 0.2341 - val_acc: 0.9113\n","\n","Epoch 00007: val_loss did not improve from 0.23348\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.1998 - acc: 0.9253 - val_loss: 0.2347 - val_acc: 0.9113\n","\n","Epoch 00008: val_loss did not improve from 0.23348\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.1962 - acc: 0.9277 - val_loss: 0.2366 - val_acc: 0.9113\n","\n","Epoch 00009: val_loss did not improve from 0.23348\n","auc-0.8779705260375363, auprc-0.5822780781450251, acc-0.9146734130634775, f1-0.4230171073094868\n","Problem type:  mort_icu\n","__________________\n","Inputs-GRU, 128, fasttext\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 380us/step - loss: 0.2173 - acc: 0.9334 - val_loss: 0.1761 - val_acc: 0.9422\n","\n","Epoch 00001: val_loss improved from inf to 0.17610, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 349us/step - loss: 0.1806 - acc: 0.9411 - val_loss: 0.1734 - val_acc: 0.9432\n","\n","Epoch 00002: val_loss improved from 0.17610 to 0.17344, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.1665 - acc: 0.9452 - val_loss: 0.1710 - val_acc: 0.9422\n","\n","Epoch 00003: val_loss improved from 0.17344 to 0.17101, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.1606 - acc: 0.9463 - val_loss: 0.1698 - val_acc: 0.9409\n","\n","Epoch 00004: val_loss improved from 0.17101 to 0.16981, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.1533 - acc: 0.9473 - val_loss: 0.1697 - val_acc: 0.9413\n","\n","Epoch 00005: val_loss improved from 0.16981 to 0.16970, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.1493 - acc: 0.9495 - val_loss: 0.1715 - val_acc: 0.9404\n","\n","Epoch 00006: val_loss did not improve from 0.16970\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 349us/step - loss: 0.1458 - acc: 0.9505 - val_loss: 0.1695 - val_acc: 0.9409\n","\n","Epoch 00007: val_loss improved from 0.16970 to 0.16947, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.1423 - acc: 0.9508 - val_loss: 0.1700 - val_acc: 0.9432\n","\n","Epoch 00008: val_loss did not improve from 0.16947\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 358us/step - loss: 0.1381 - acc: 0.9526 - val_loss: 0.1709 - val_acc: 0.9418\n","\n","Epoch 00009: val_loss did not improve from 0.16947\n","Epoch 10/100\n","15219/15219 [==============================] - 5s 360us/step - loss: 0.1359 - acc: 0.9537 - val_loss: 0.1710 - val_acc: 0.9399\n","\n","Epoch 00010: val_loss did not improve from 0.16947\n","Epoch 11/100\n","15219/15219 [==============================] - 5s 355us/step - loss: 0.1339 - acc: 0.9536 - val_loss: 0.1699 - val_acc: 0.9413\n","\n","Epoch 00011: val_loss did not improve from 0.16947\n","Epoch 12/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.1321 - acc: 0.9545 - val_loss: 0.1703 - val_acc: 0.9381\n","\n","Epoch 00012: val_loss did not improve from 0.16947\n","auc-0.8904068542534762, auprc-0.5285738276317108, acc-0.9408923643054278, f1-0.44251626898047725\n","Problem type:  los_3\n","__________________\n","Inputs-GRU, 128, fasttext\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 381us/step - loss: 0.5973 - acc: 0.7154 - val_loss: 0.5657 - val_acc: 0.7366\n","\n","Epoch 00001: val_loss improved from inf to 0.56572, saving model to avg-fasttext-los_3-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.5493 - acc: 0.7387 - val_loss: 0.5481 - val_acc: 0.7426\n","\n","Epoch 00002: val_loss improved from 0.56572 to 0.54808, saving model to avg-fasttext-los_3-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.5315 - acc: 0.7490 - val_loss: 0.5502 - val_acc: 0.7440\n","\n","Epoch 00003: val_loss did not improve from 0.54808\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.5263 - acc: 0.7513 - val_loss: 0.5458 - val_acc: 0.7463\n","\n","Epoch 00004: val_loss improved from 0.54808 to 0.54577, saving model to avg-fasttext-los_3-best_model.hdf5\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 348us/step - loss: 0.5185 - acc: 0.7564 - val_loss: 0.5434 - val_acc: 0.7454\n","\n","Epoch 00005: val_loss improved from 0.54577 to 0.54341, saving model to avg-fasttext-los_3-best_model.hdf5\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 355us/step - loss: 0.5159 - acc: 0.7577 - val_loss: 0.5436 - val_acc: 0.7458\n","\n","Epoch 00006: val_loss did not improve from 0.54341\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 356us/step - loss: 0.5107 - acc: 0.7608 - val_loss: 0.5432 - val_acc: 0.7472\n","\n","Epoch 00007: val_loss improved from 0.54341 to 0.54325, saving model to avg-fasttext-los_3-best_model.hdf5\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.5066 - acc: 0.7633 - val_loss: 0.5440 - val_acc: 0.7458\n","\n","Epoch 00008: val_loss did not improve from 0.54325\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.5053 - acc: 0.7649 - val_loss: 0.5429 - val_acc: 0.7468\n","\n","Epoch 00009: val_loss improved from 0.54325 to 0.54293, saving model to avg-fasttext-los_3-best_model.hdf5\n","Epoch 10/100\n","15219/15219 [==============================] - 5s 349us/step - loss: 0.5040 - acc: 0.7656 - val_loss: 0.5426 - val_acc: 0.7445\n","\n","Epoch 00010: val_loss improved from 0.54293 to 0.54255, saving model to avg-fasttext-los_3-best_model.hdf5\n","Epoch 11/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.4998 - acc: 0.7692 - val_loss: 0.5421 - val_acc: 0.7491\n","\n","Epoch 00011: val_loss improved from 0.54255 to 0.54208, saving model to avg-fasttext-los_3-best_model.hdf5\n","Epoch 12/100\n","15219/15219 [==============================] - 5s 356us/step - loss: 0.4970 - acc: 0.7700 - val_loss: 0.5430 - val_acc: 0.7500\n","\n","Epoch 00012: val_loss did not improve from 0.54208\n","Epoch 13/100\n","15219/15219 [==============================] - 6s 368us/step - loss: 0.4930 - acc: 0.7717 - val_loss: 0.5431 - val_acc: 0.7472\n","\n","Epoch 00013: val_loss did not improve from 0.54208\n","Epoch 14/100\n","15219/15219 [==============================] - 6s 371us/step - loss: 0.4939 - acc: 0.7708 - val_loss: 0.5426 - val_acc: 0.7454\n","\n","Epoch 00014: val_loss did not improve from 0.54208\n","Epoch 15/100\n","15219/15219 [==============================] - 5s 359us/step - loss: 0.4913 - acc: 0.7730 - val_loss: 0.5443 - val_acc: 0.7468\n","\n","Epoch 00015: val_loss did not improve from 0.54208\n","Epoch 16/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.4910 - acc: 0.7740 - val_loss: 0.5426 - val_acc: 0.7468\n","\n","Epoch 00016: val_loss did not improve from 0.54208\n","auc-0.7091347664192574, auprc-0.4919540190908021, acc-0.7419503219871205, f1-0.36753100338218714\n","Problem type:  los_7\n","__________________\n","Inputs-GRU, 128, fasttext\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 403us/step - loss: 0.3103 - acc: 0.9116 - val_loss: 0.2658 - val_acc: 0.9228\n","\n","Epoch 00001: val_loss improved from inf to 0.26582, saving model to avg-fasttext-los_7-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 361us/step - loss: 0.2639 - acc: 0.9199 - val_loss: 0.2628 - val_acc: 0.9242\n","\n","Epoch 00002: val_loss improved from 0.26582 to 0.26277, saving model to avg-fasttext-los_7-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 359us/step - loss: 0.2538 - acc: 0.9202 - val_loss: 0.2622 - val_acc: 0.9242\n","\n","Epoch 00003: val_loss improved from 0.26277 to 0.26225, saving model to avg-fasttext-los_7-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 358us/step - loss: 0.2468 - acc: 0.9215 - val_loss: 0.2633 - val_acc: 0.9238\n","\n","Epoch 00004: val_loss did not improve from 0.26225\n","Epoch 5/100\n","15219/15219 [==============================] - 6s 363us/step - loss: 0.2446 - acc: 0.9223 - val_loss: 0.2628 - val_acc: 0.9242\n","\n","Epoch 00005: val_loss did not improve from 0.26225\n","Epoch 6/100\n","15219/15219 [==============================] - 6s 366us/step - loss: 0.2413 - acc: 0.9227 - val_loss: 0.2614 - val_acc: 0.9238\n","\n","Epoch 00006: val_loss improved from 0.26225 to 0.26141, saving model to avg-fasttext-los_7-best_model.hdf5\n","Epoch 7/100\n","15219/15219 [==============================] - 6s 364us/step - loss: 0.2380 - acc: 0.9224 - val_loss: 0.2622 - val_acc: 0.9242\n","\n","Epoch 00007: val_loss did not improve from 0.26141\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 358us/step - loss: 0.2351 - acc: 0.9228 - val_loss: 0.2627 - val_acc: 0.9247\n","\n","Epoch 00008: val_loss did not improve from 0.26141\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 358us/step - loss: 0.2341 - acc: 0.9229 - val_loss: 0.2609 - val_acc: 0.9238\n","\n","Epoch 00009: val_loss improved from 0.26141 to 0.26087, saving model to avg-fasttext-los_7-best_model.hdf5\n","Epoch 10/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.2318 - acc: 0.9233 - val_loss: 0.2613 - val_acc: 0.9238\n","\n","Epoch 00010: val_loss did not improve from 0.26087\n","Epoch 11/100\n","15219/15219 [==============================] - 5s 359us/step - loss: 0.2299 - acc: 0.9230 - val_loss: 0.2613 - val_acc: 0.9242\n","\n","Epoch 00011: val_loss did not improve from 0.26087\n","Epoch 12/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.2270 - acc: 0.9239 - val_loss: 0.2617 - val_acc: 0.9242\n","\n","Epoch 00012: val_loss did not improve from 0.26087\n","Epoch 13/100\n","15219/15219 [==============================] - 5s 360us/step - loss: 0.2257 - acc: 0.9231 - val_loss: 0.2619 - val_acc: 0.9228\n","\n","Epoch 00013: val_loss did not improve from 0.26087\n","Epoch 14/100\n","15219/15219 [==============================] - 5s 358us/step - loss: 0.2245 - acc: 0.9237 - val_loss: 0.2621 - val_acc: 0.9233\n","\n","Epoch 00014: val_loss did not improve from 0.26087\n","auc-0.7337089910157394, auprc-0.21908113476321034, acc-0.9181232750689973, f1-0.03783783783783784\n","Embedding:  concat\n","=============================\n","Iteration number:  1\n","Problem type:  mort_hosp\n","__________________\n","Inputs-GRU, 128, concat\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 376us/step - loss: 0.2917 - acc: 0.8986 - val_loss: 0.2383 - val_acc: 0.9164\n","\n","Epoch 00001: val_loss improved from inf to 0.23828, saving model to avg-concat-mort_hosp-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 346us/step - loss: 0.2408 - acc: 0.9147 - val_loss: 0.2393 - val_acc: 0.9159\n","\n","Epoch 00002: val_loss did not improve from 0.23828\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.2273 - acc: 0.9201 - val_loss: 0.2365 - val_acc: 0.9164\n","\n","Epoch 00003: val_loss improved from 0.23828 to 0.23653, saving model to avg-concat-mort_hosp-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.2199 - acc: 0.9220 - val_loss: 0.2345 - val_acc: 0.9136\n","\n","Epoch 00004: val_loss improved from 0.23653 to 0.23446, saving model to avg-concat-mort_hosp-best_model.hdf5\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.2124 - acc: 0.9242 - val_loss: 0.2338 - val_acc: 0.9145\n","\n","Epoch 00005: val_loss improved from 0.23446 to 0.23380, saving model to avg-concat-mort_hosp-best_model.hdf5\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.2074 - acc: 0.9252 - val_loss: 0.2378 - val_acc: 0.9145\n","\n","Epoch 00006: val_loss did not improve from 0.23380\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 349us/step - loss: 0.2036 - acc: 0.9252 - val_loss: 0.2326 - val_acc: 0.9131\n","\n","Epoch 00007: val_loss improved from 0.23380 to 0.23255, saving model to avg-concat-mort_hosp-best_model.hdf5\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.1988 - acc: 0.9285 - val_loss: 0.2342 - val_acc: 0.9140\n","\n","Epoch 00008: val_loss did not improve from 0.23255\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 361us/step - loss: 0.1963 - acc: 0.9281 - val_loss: 0.2357 - val_acc: 0.9145\n","\n","Epoch 00009: val_loss did not improve from 0.23255\n","Epoch 10/100\n","15219/15219 [==============================] - 5s 348us/step - loss: 0.1942 - acc: 0.9301 - val_loss: 0.2368 - val_acc: 0.9150\n","\n","Epoch 00010: val_loss did not improve from 0.23255\n","Epoch 11/100\n","15219/15219 [==============================] - 5s 349us/step - loss: 0.1899 - acc: 0.9303 - val_loss: 0.2348 - val_acc: 0.9140\n","\n","Epoch 00011: val_loss did not improve from 0.23255\n","Epoch 12/100\n","15219/15219 [==============================] - 5s 355us/step - loss: 0.1893 - acc: 0.9321 - val_loss: 0.2362 - val_acc: 0.9140\n","\n","Epoch 00012: val_loss did not improve from 0.23255\n","auc-0.8756176204951979, auprc-0.5758709042130064, acc-0.9128334866605335, f1-0.44509516837481694\n","Problem type:  mort_icu\n","__________________\n","Inputs-GRU, 128, concat\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 372us/step - loss: 0.2308 - acc: 0.9290 - val_loss: 0.1805 - val_acc: 0.9399\n","\n","Epoch 00001: val_loss improved from inf to 0.18054, saving model to avg-concat-mort_icu-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.1785 - acc: 0.9410 - val_loss: 0.1771 - val_acc: 0.9404\n","\n","Epoch 00002: val_loss improved from 0.18054 to 0.17710, saving model to avg-concat-mort_icu-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.1661 - acc: 0.9439 - val_loss: 0.1761 - val_acc: 0.9413\n","\n","Epoch 00003: val_loss improved from 0.17710 to 0.17608, saving model to avg-concat-mort_icu-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 347us/step - loss: 0.1584 - acc: 0.9467 - val_loss: 0.1748 - val_acc: 0.9436\n","\n","Epoch 00004: val_loss improved from 0.17608 to 0.17484, saving model to avg-concat-mort_icu-best_model.hdf5\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 343us/step - loss: 0.1534 - acc: 0.9486 - val_loss: 0.1761 - val_acc: 0.9413\n","\n","Epoch 00005: val_loss did not improve from 0.17484\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 348us/step - loss: 0.1487 - acc: 0.9494 - val_loss: 0.1749 - val_acc: 0.9404\n","\n","Epoch 00006: val_loss did not improve from 0.17484\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 347us/step - loss: 0.1455 - acc: 0.9501 - val_loss: 0.1750 - val_acc: 0.9390\n","\n","Epoch 00007: val_loss did not improve from 0.17484\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.1407 - acc: 0.9517 - val_loss: 0.1749 - val_acc: 0.9385\n","\n","Epoch 00008: val_loss did not improve from 0.17484\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.1381 - acc: 0.9522 - val_loss: 0.1762 - val_acc: 0.9427\n","\n","Epoch 00009: val_loss did not improve from 0.17484\n","auc-0.8805210918114145, auprc-0.5035549458665224, acc-0.9402023919043239, f1-0.38967136150234744\n","Problem type:  los_3\n","__________________\n","Inputs-GRU, 128, concat\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 373us/step - loss: 0.6005 - acc: 0.7129 - val_loss: 0.5616 - val_acc: 0.7334\n","\n","Epoch 00001: val_loss improved from inf to 0.56163, saving model to avg-concat-los_3-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.5427 - acc: 0.7413 - val_loss: 0.5514 - val_acc: 0.7403\n","\n","Epoch 00002: val_loss improved from 0.56163 to 0.55138, saving model to avg-concat-los_3-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.5276 - acc: 0.7487 - val_loss: 0.5450 - val_acc: 0.7463\n","\n","Epoch 00003: val_loss improved from 0.55138 to 0.54495, saving model to avg-concat-los_3-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 347us/step - loss: 0.5210 - acc: 0.7514 - val_loss: 0.5459 - val_acc: 0.7463\n","\n","Epoch 00004: val_loss did not improve from 0.54495\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.5149 - acc: 0.7572 - val_loss: 0.5447 - val_acc: 0.7449\n","\n","Epoch 00005: val_loss improved from 0.54495 to 0.54465, saving model to avg-concat-los_3-best_model.hdf5\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 345us/step - loss: 0.5089 - acc: 0.7606 - val_loss: 0.5447 - val_acc: 0.7463\n","\n","Epoch 00006: val_loss did not improve from 0.54465\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 344us/step - loss: 0.5047 - acc: 0.7631 - val_loss: 0.5430 - val_acc: 0.7454\n","\n","Epoch 00007: val_loss improved from 0.54465 to 0.54299, saving model to avg-concat-los_3-best_model.hdf5\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 355us/step - loss: 0.5023 - acc: 0.7649 - val_loss: 0.5465 - val_acc: 0.7458\n","\n","Epoch 00008: val_loss did not improve from 0.54299\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.5003 - acc: 0.7630 - val_loss: 0.5451 - val_acc: 0.7477\n","\n","Epoch 00009: val_loss did not improve from 0.54299\n","Epoch 10/100\n","15219/15219 [==============================] - 5s 344us/step - loss: 0.4969 - acc: 0.7660 - val_loss: 0.5431 - val_acc: 0.7495\n","\n","Epoch 00010: val_loss did not improve from 0.54299\n","Epoch 11/100\n","15219/15219 [==============================] - 5s 346us/step - loss: 0.4962 - acc: 0.7642 - val_loss: 0.5443 - val_acc: 0.7468\n","\n","Epoch 00011: val_loss did not improve from 0.54299\n","Epoch 12/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.4917 - acc: 0.7688 - val_loss: 0.5447 - val_acc: 0.7449\n","\n","Epoch 00012: val_loss did not improve from 0.54299\n","auc-0.7078840401932824, auprc-0.48458812571038135, acc-0.7401103955841767, f1-0.3777533039647577\n","Problem type:  los_7\n","__________________\n","Inputs-GRU, 128, concat\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 384us/step - loss: 0.2903 - acc: 0.9178 - val_loss: 0.2705 - val_acc: 0.9228\n","\n","Epoch 00001: val_loss improved from inf to 0.27050, saving model to avg-concat-los_7-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.2573 - acc: 0.9212 - val_loss: 0.2660 - val_acc: 0.9238\n","\n","Epoch 00002: val_loss improved from 0.27050 to 0.26605, saving model to avg-concat-los_7-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 6s 370us/step - loss: 0.2496 - acc: 0.9215 - val_loss: 0.2669 - val_acc: 0.9233\n","\n","Epoch 00003: val_loss did not improve from 0.26605\n","Epoch 4/100\n","15219/15219 [==============================] - 6s 363us/step - loss: 0.2415 - acc: 0.9215 - val_loss: 0.2654 - val_acc: 0.9238\n","\n","Epoch 00004: val_loss improved from 0.26605 to 0.26541, saving model to avg-concat-los_7-best_model.hdf5\n","Epoch 5/100\n","15219/15219 [==============================] - 6s 366us/step - loss: 0.2389 - acc: 0.9224 - val_loss: 0.2673 - val_acc: 0.9238\n","\n","Epoch 00005: val_loss did not improve from 0.26541\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.2352 - acc: 0.9229 - val_loss: 0.2659 - val_acc: 0.9238\n","\n","Epoch 00006: val_loss did not improve from 0.26541\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.2329 - acc: 0.9231 - val_loss: 0.2675 - val_acc: 0.9238\n","\n","Epoch 00007: val_loss did not improve from 0.26541\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 360us/step - loss: 0.2301 - acc: 0.9232 - val_loss: 0.2659 - val_acc: 0.9233\n","\n","Epoch 00008: val_loss did not improve from 0.26541\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 359us/step - loss: 0.2278 - acc: 0.9237 - val_loss: 0.2669 - val_acc: 0.9233\n","\n","Epoch 00009: val_loss did not improve from 0.26541\n","auc-0.7254326067866069, auprc-0.20346022766744978, acc-0.9178932842686293, f1-0.016528925619834708\n","Hidden unit:  256\n","Embedding:  word2vec\n","=============================\n","Iteration number:  1\n","Problem type:  mort_hosp\n","__________________\n","Inputs-GRU, 256, word2vec\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 379us/step - loss: 0.2748 - acc: 0.9052 - val_loss: 0.2386 - val_acc: 0.9117\n","\n","Epoch 00001: val_loss improved from inf to 0.23863, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 348us/step - loss: 0.2337 - acc: 0.9160 - val_loss: 0.2327 - val_acc: 0.9168\n","\n","Epoch 00002: val_loss improved from 0.23863 to 0.23270, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 347us/step - loss: 0.2177 - acc: 0.9207 - val_loss: 0.2279 - val_acc: 0.9154\n","\n","Epoch 00003: val_loss improved from 0.23270 to 0.22788, saving model to avg-word2vec-mort_hosp-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.2094 - acc: 0.9239 - val_loss: 0.2284 - val_acc: 0.9127\n","\n","Epoch 00004: val_loss did not improve from 0.22788\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 356us/step - loss: 0.2024 - acc: 0.9248 - val_loss: 0.2325 - val_acc: 0.9136\n","\n","Epoch 00005: val_loss did not improve from 0.22788\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.1981 - acc: 0.9272 - val_loss: 0.2309 - val_acc: 0.9154\n","\n","Epoch 00006: val_loss did not improve from 0.22788\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.1925 - acc: 0.9283 - val_loss: 0.2321 - val_acc: 0.9168\n","\n","Epoch 00007: val_loss did not improve from 0.22788\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.1869 - acc: 0.9305 - val_loss: 0.2319 - val_acc: 0.9136\n","\n","Epoch 00008: val_loss did not improve from 0.22788\n","auc-0.8793478500308397, auprc-0.5881763419305859, acc-0.9181232750689973, f1-0.4523076923076923\n","Problem type:  mort_icu\n","__________________\n","Inputs-GRU, 256, word2vec\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 385us/step - loss: 0.2049 - acc: 0.9367 - val_loss: 0.1705 - val_acc: 0.9432\n","\n","Epoch 00001: val_loss improved from inf to 0.17045, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.1696 - acc: 0.9440 - val_loss: 0.1690 - val_acc: 0.9436\n","\n","Epoch 00002: val_loss improved from 0.17045 to 0.16900, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.1561 - acc: 0.9485 - val_loss: 0.1680 - val_acc: 0.9404\n","\n","Epoch 00003: val_loss improved from 0.16900 to 0.16798, saving model to avg-word2vec-mort_icu-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.1481 - acc: 0.9492 - val_loss: 0.1690 - val_acc: 0.9432\n","\n","Epoch 00004: val_loss did not improve from 0.16798\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 355us/step - loss: 0.1416 - acc: 0.9522 - val_loss: 0.1695 - val_acc: 0.9422\n","\n","Epoch 00005: val_loss did not improve from 0.16798\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 349us/step - loss: 0.1361 - acc: 0.9538 - val_loss: 0.1708 - val_acc: 0.9422\n","\n","Epoch 00006: val_loss did not improve from 0.16798\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.1322 - acc: 0.9554 - val_loss: 0.1712 - val_acc: 0.9427\n","\n","Epoch 00007: val_loss did not improve from 0.16798\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.1278 - acc: 0.9562 - val_loss: 0.1728 - val_acc: 0.9404\n","\n","Epoch 00008: val_loss did not improve from 0.16798\n","auc-0.8869633409803829, auprc-0.5319617559182519, acc-0.9431922723091076, f1-0.48648648648648646\n","Problem type:  los_3\n","__________________\n","Inputs-GRU, 256, word2vec\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 378us/step - loss: 0.5800 - acc: 0.7270 - val_loss: 0.5419 - val_acc: 0.7421\n","\n","Epoch 00001: val_loss improved from inf to 0.54188, saving model to avg-word2vec-los_3-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 361us/step - loss: 0.5343 - acc: 0.7480 - val_loss: 0.5344 - val_acc: 0.7495\n","\n","Epoch 00002: val_loss improved from 0.54188 to 0.53437, saving model to avg-word2vec-los_3-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.5188 - acc: 0.7563 - val_loss: 0.5365 - val_acc: 0.7486\n","\n","Epoch 00003: val_loss did not improve from 0.53437\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.5104 - acc: 0.7609 - val_loss: 0.5323 - val_acc: 0.7514\n","\n","Epoch 00004: val_loss improved from 0.53437 to 0.53232, saving model to avg-word2vec-los_3-best_model.hdf5\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 361us/step - loss: 0.5026 - acc: 0.7661 - val_loss: 0.5323 - val_acc: 0.7528\n","\n","Epoch 00005: val_loss improved from 0.53232 to 0.53228, saving model to avg-word2vec-los_3-best_model.hdf5\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.4968 - acc: 0.7677 - val_loss: 0.5328 - val_acc: 0.7505\n","\n","Epoch 00006: val_loss did not improve from 0.53228\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.4913 - acc: 0.7755 - val_loss: 0.5326 - val_acc: 0.7532\n","\n","Epoch 00007: val_loss did not improve from 0.53228\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.4859 - acc: 0.7776 - val_loss: 0.5336 - val_acc: 0.7528\n","\n","Epoch 00008: val_loss did not improve from 0.53228\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 356us/step - loss: 0.4813 - acc: 0.7811 - val_loss: 0.5348 - val_acc: 0.7482\n","\n","Epoch 00009: val_loss did not improve from 0.53228\n","Epoch 10/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.4759 - acc: 0.7813 - val_loss: 0.5350 - val_acc: 0.7482\n","\n","Epoch 00010: val_loss did not improve from 0.53228\n","auc-0.7174508392137696, auprc-0.5021809956612135, acc-0.7479300827966882, f1-0.39043381535038935\n","Problem type:  los_7\n","__________________\n","Inputs-GRU, 256, word2vec\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 380us/step - loss: 0.2874 - acc: 0.9155 - val_loss: 0.2690 - val_acc: 0.9228\n","\n","Epoch 00001: val_loss improved from inf to 0.26895, saving model to avg-word2vec-los_7-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.2531 - acc: 0.9223 - val_loss: 0.2628 - val_acc: 0.9238\n","\n","Epoch 00002: val_loss improved from 0.26895 to 0.26278, saving model to avg-word2vec-los_7-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 355us/step - loss: 0.2437 - acc: 0.9222 - val_loss: 0.2674 - val_acc: 0.9242\n","\n","Epoch 00003: val_loss did not improve from 0.26278\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 349us/step - loss: 0.2384 - acc: 0.9226 - val_loss: 0.2655 - val_acc: 0.9238\n","\n","Epoch 00004: val_loss did not improve from 0.26278\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.2336 - acc: 0.9232 - val_loss: 0.2629 - val_acc: 0.9251\n","\n","Epoch 00005: val_loss did not improve from 0.26278\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.2282 - acc: 0.9238 - val_loss: 0.2647 - val_acc: 0.9224\n","\n","Epoch 00006: val_loss did not improve from 0.26278\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.2239 - acc: 0.9249 - val_loss: 0.2660 - val_acc: 0.9228\n","\n","Epoch 00007: val_loss did not improve from 0.26278\n","auc-0.7249850825245998, auprc-0.21163941744228756, acc-0.9183532658693653, f1-0.022038567493112945\n","Embedding:  fasttext\n","=============================\n","Iteration number:  1\n","Problem type:  mort_hosp\n","__________________\n","Inputs-GRU, 256, fasttext\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 386us/step - loss: 0.2821 - acc: 0.9024 - val_loss: 0.2418 - val_acc: 0.9122\n","\n","Epoch 00001: val_loss improved from inf to 0.24179, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.2331 - acc: 0.9154 - val_loss: 0.2314 - val_acc: 0.9136\n","\n","Epoch 00002: val_loss improved from 0.24179 to 0.23142, saving model to avg-fasttext-mort_hosp-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.2193 - acc: 0.9229 - val_loss: 0.2371 - val_acc: 0.9122\n","\n","Epoch 00003: val_loss did not improve from 0.23142\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 348us/step - loss: 0.2098 - acc: 0.9236 - val_loss: 0.2320 - val_acc: 0.9164\n","\n","Epoch 00004: val_loss did not improve from 0.23142\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 360us/step - loss: 0.2023 - acc: 0.9254 - val_loss: 0.2340 - val_acc: 0.9117\n","\n","Epoch 00005: val_loss did not improve from 0.23142\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 356us/step - loss: 0.1950 - acc: 0.9304 - val_loss: 0.2328 - val_acc: 0.9127\n","\n","Epoch 00006: val_loss did not improve from 0.23142\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 358us/step - loss: 0.1905 - acc: 0.9319 - val_loss: 0.2347 - val_acc: 0.9136\n","\n","Epoch 00007: val_loss did not improve from 0.23142\n","auc-0.8728527843862895, auprc-0.5722360605109263, acc-0.9149034038638455, f1-0.4444444444444444\n","Problem type:  mort_icu\n","__________________\n","Inputs-GRU, 256, fasttext\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 390us/step - loss: 0.2363 - acc: 0.9277 - val_loss: 0.1739 - val_acc: 0.9418\n","\n","Epoch 00001: val_loss improved from inf to 0.17391, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.1766 - acc: 0.9428 - val_loss: 0.1717 - val_acc: 0.9404\n","\n","Epoch 00002: val_loss improved from 0.17391 to 0.17172, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.1627 - acc: 0.9465 - val_loss: 0.1743 - val_acc: 0.9409\n","\n","Epoch 00003: val_loss did not improve from 0.17172\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.1548 - acc: 0.9486 - val_loss: 0.1725 - val_acc: 0.9427\n","\n","Epoch 00004: val_loss did not improve from 0.17172\n","Epoch 5/100\n","15219/15219 [==============================] - 6s 368us/step - loss: 0.1471 - acc: 0.9499 - val_loss: 0.1680 - val_acc: 0.9418\n","\n","Epoch 00005: val_loss improved from 0.17172 to 0.16798, saving model to avg-fasttext-mort_icu-best_model.hdf5\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 361us/step - loss: 0.1419 - acc: 0.9523 - val_loss: 0.1721 - val_acc: 0.9418\n","\n","Epoch 00006: val_loss did not improve from 0.16798\n","Epoch 7/100\n","15219/15219 [==============================] - 6s 369us/step - loss: 0.1364 - acc: 0.9528 - val_loss: 0.1759 - val_acc: 0.9399\n","\n","Epoch 00007: val_loss did not improve from 0.16798\n","Epoch 8/100\n","15219/15219 [==============================] - 6s 371us/step - loss: 0.1313 - acc: 0.9548 - val_loss: 0.1705 - val_acc: 0.9422\n","\n","Epoch 00008: val_loss did not improve from 0.16798\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 361us/step - loss: 0.1281 - acc: 0.9566 - val_loss: 0.1748 - val_acc: 0.9422\n","\n","Epoch 00009: val_loss did not improve from 0.16798\n","Epoch 10/100\n","15219/15219 [==============================] - 6s 364us/step - loss: 0.1240 - acc: 0.9570 - val_loss: 0.1763 - val_acc: 0.9376\n","\n","Epoch 00010: val_loss did not improve from 0.16798\n","auc-0.8868263963668711, auprc-0.5241172330797109, acc-0.9404323827046918, f1-0.4477611940298507\n","Problem type:  los_3\n","__________________\n","Inputs-GRU, 256, fasttext\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 382us/step - loss: 0.5978 - acc: 0.7184 - val_loss: 0.5472 - val_acc: 0.7412\n","\n","Epoch 00001: val_loss improved from inf to 0.54719, saving model to avg-fasttext-los_3-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.5411 - acc: 0.7469 - val_loss: 0.5436 - val_acc: 0.7477\n","\n","Epoch 00002: val_loss improved from 0.54719 to 0.54357, saving model to avg-fasttext-los_3-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 355us/step - loss: 0.5239 - acc: 0.7549 - val_loss: 0.5405 - val_acc: 0.7477\n","\n","Epoch 00003: val_loss improved from 0.54357 to 0.54053, saving model to avg-fasttext-los_3-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.5144 - acc: 0.7568 - val_loss: 0.5407 - val_acc: 0.7477\n","\n","Epoch 00004: val_loss did not improve from 0.54053\n","Epoch 5/100\n","15219/15219 [==============================] - 6s 363us/step - loss: 0.5095 - acc: 0.7613 - val_loss: 0.5422 - val_acc: 0.7458\n","\n","Epoch 00005: val_loss did not improve from 0.54053\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.5005 - acc: 0.7683 - val_loss: 0.5414 - val_acc: 0.7482\n","\n","Epoch 00006: val_loss did not improve from 0.54053\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 347us/step - loss: 0.4947 - acc: 0.7709 - val_loss: 0.5384 - val_acc: 0.7449\n","\n","Epoch 00007: val_loss improved from 0.54053 to 0.53837, saving model to avg-fasttext-los_3-best_model.hdf5\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.4877 - acc: 0.7738 - val_loss: 0.5398 - val_acc: 0.7440\n","\n","Epoch 00008: val_loss did not improve from 0.53837\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 349us/step - loss: 0.4839 - acc: 0.7747 - val_loss: 0.5413 - val_acc: 0.7486\n","\n","Epoch 00009: val_loss did not improve from 0.53837\n","Epoch 10/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.4795 - acc: 0.7773 - val_loss: 0.5429 - val_acc: 0.7421\n","\n","Epoch 00010: val_loss did not improve from 0.53837\n","Epoch 11/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.4769 - acc: 0.7797 - val_loss: 0.5457 - val_acc: 0.7389\n","\n","Epoch 00011: val_loss did not improve from 0.53837\n","Epoch 12/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.4712 - acc: 0.7860 - val_loss: 0.5449 - val_acc: 0.7366\n","\n","Epoch 00012: val_loss did not improve from 0.53837\n","auc-0.7048334232120136, auprc-0.49265415005837176, acc-0.7426402943882244, f1-0.3660056657223797\n","Problem type:  los_7\n","__________________\n","Inputs-GRU, 256, fasttext\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 385us/step - loss: 0.2932 - acc: 0.9160 - val_loss: 0.2670 - val_acc: 0.9210\n","\n","Epoch 00001: val_loss improved from inf to 0.26696, saving model to avg-fasttext-los_7-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 359us/step - loss: 0.2560 - acc: 0.9210 - val_loss: 0.2620 - val_acc: 0.9238\n","\n","Epoch 00002: val_loss improved from 0.26696 to 0.26205, saving model to avg-fasttext-los_7-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.2446 - acc: 0.9227 - val_loss: 0.2636 - val_acc: 0.9247\n","\n","Epoch 00003: val_loss did not improve from 0.26205\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 359us/step - loss: 0.2402 - acc: 0.9231 - val_loss: 0.2639 - val_acc: 0.9247\n","\n","Epoch 00004: val_loss did not improve from 0.26205\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.2334 - acc: 0.9237 - val_loss: 0.2614 - val_acc: 0.9247\n","\n","Epoch 00005: val_loss improved from 0.26205 to 0.26141, saving model to avg-fasttext-los_7-best_model.hdf5\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.2290 - acc: 0.9240 - val_loss: 0.2605 - val_acc: 0.9242\n","\n","Epoch 00006: val_loss improved from 0.26141 to 0.26046, saving model to avg-fasttext-los_7-best_model.hdf5\n","Epoch 7/100\n","15219/15219 [==============================] - 6s 363us/step - loss: 0.2245 - acc: 0.9239 - val_loss: 0.2635 - val_acc: 0.9242\n","\n","Epoch 00007: val_loss did not improve from 0.26046\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.2198 - acc: 0.9249 - val_loss: 0.2621 - val_acc: 0.9247\n","\n","Epoch 00008: val_loss did not improve from 0.26046\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.2139 - acc: 0.9265 - val_loss: 0.2625 - val_acc: 0.9228\n","\n","Epoch 00009: val_loss did not improve from 0.26046\n","Epoch 10/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.2116 - acc: 0.9271 - val_loss: 0.2645 - val_acc: 0.9205\n","\n","Epoch 00010: val_loss did not improve from 0.26046\n","Epoch 11/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.2087 - acc: 0.9263 - val_loss: 0.2641 - val_acc: 0.9210\n","\n","Epoch 00011: val_loss did not improve from 0.26046\n","auc-0.7190543305712549, auprc-0.21520013818805922, acc-0.9188132474701012, f1-0.048517520215633415\n","Embedding:  concat\n","=============================\n","Iteration number:  1\n","Problem type:  mort_hosp\n","__________________\n","Inputs-GRU, 256, concat\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 384us/step - loss: 0.3037 - acc: 0.8962 - val_loss: 0.2450 - val_acc: 0.9127\n","\n","Epoch 00001: val_loss improved from inf to 0.24501, saving model to avg-concat-mort_hosp-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.2365 - acc: 0.9164 - val_loss: 0.2411 - val_acc: 0.9099\n","\n","Epoch 00002: val_loss improved from 0.24501 to 0.24112, saving model to avg-concat-mort_hosp-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.2223 - acc: 0.9209 - val_loss: 0.2344 - val_acc: 0.9127\n","\n","Epoch 00003: val_loss improved from 0.24112 to 0.23445, saving model to avg-concat-mort_hosp-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.2109 - acc: 0.9236 - val_loss: 0.2358 - val_acc: 0.9122\n","\n","Epoch 00004: val_loss did not improve from 0.23445\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.2037 - acc: 0.9263 - val_loss: 0.2324 - val_acc: 0.9127\n","\n","Epoch 00005: val_loss improved from 0.23445 to 0.23245, saving model to avg-concat-mort_hosp-best_model.hdf5\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.1961 - acc: 0.9281 - val_loss: 0.2340 - val_acc: 0.9136\n","\n","Epoch 00006: val_loss did not improve from 0.23245\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 361us/step - loss: 0.1910 - acc: 0.9289 - val_loss: 0.2346 - val_acc: 0.9136\n","\n","Epoch 00007: val_loss did not improve from 0.23245\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 356us/step - loss: 0.1877 - acc: 0.9300 - val_loss: 0.2351 - val_acc: 0.9113\n","\n","Epoch 00008: val_loss did not improve from 0.23245\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.1812 - acc: 0.9344 - val_loss: 0.2399 - val_acc: 0.9113\n","\n","Epoch 00009: val_loss did not improve from 0.23245\n","Epoch 10/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.1792 - acc: 0.9344 - val_loss: 0.2386 - val_acc: 0.9108\n","\n","Epoch 00010: val_loss did not improve from 0.23245\n","auc-0.871962287426205, auprc-0.5774628017915371, acc-0.9167433302667893, f1-0.5041095890410959\n","Problem type:  mort_icu\n","__________________\n","Inputs-GRU, 256, concat\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 379us/step - loss: 0.2183 - acc: 0.9320 - val_loss: 0.1891 - val_acc: 0.9399\n","\n","Epoch 00001: val_loss improved from inf to 0.18911, saving model to avg-concat-mort_icu-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.1725 - acc: 0.9430 - val_loss: 0.1777 - val_acc: 0.9413\n","\n","Epoch 00002: val_loss improved from 0.18911 to 0.17768, saving model to avg-concat-mort_icu-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 356us/step - loss: 0.1573 - acc: 0.9477 - val_loss: 0.1734 - val_acc: 0.9422\n","\n","Epoch 00003: val_loss improved from 0.17768 to 0.17341, saving model to avg-concat-mort_icu-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 358us/step - loss: 0.1481 - acc: 0.9494 - val_loss: 0.1739 - val_acc: 0.9413\n","\n","Epoch 00004: val_loss did not improve from 0.17341\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 361us/step - loss: 0.1432 - acc: 0.9508 - val_loss: 0.1762 - val_acc: 0.9372\n","\n","Epoch 00005: val_loss did not improve from 0.17341\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 355us/step - loss: 0.1360 - acc: 0.9526 - val_loss: 0.1765 - val_acc: 0.9432\n","\n","Epoch 00006: val_loss did not improve from 0.17341\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.1311 - acc: 0.9553 - val_loss: 0.1800 - val_acc: 0.9395\n","\n","Epoch 00007: val_loss did not improve from 0.17341\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 357us/step - loss: 0.1267 - acc: 0.9553 - val_loss: 0.1832 - val_acc: 0.9399\n","\n","Epoch 00008: val_loss did not improve from 0.17341\n","auc-0.8859099208764456, auprc-0.5165119182599262, acc-0.9408923643054278, f1-0.41986455981941306\n","Problem type:  los_3\n","__________________\n","Inputs-GRU, 256, concat\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 385us/step - loss: 0.6029 - acc: 0.7123 - val_loss: 0.5492 - val_acc: 0.7431\n","\n","Epoch 00001: val_loss improved from inf to 0.54920, saving model to avg-concat-los_3-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.5385 - acc: 0.7441 - val_loss: 0.5439 - val_acc: 0.7482\n","\n","Epoch 00002: val_loss improved from 0.54920 to 0.54394, saving model to avg-concat-los_3-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 353us/step - loss: 0.5220 - acc: 0.7546 - val_loss: 0.5404 - val_acc: 0.7509\n","\n","Epoch 00003: val_loss improved from 0.54394 to 0.54039, saving model to avg-concat-los_3-best_model.hdf5\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 351us/step - loss: 0.5134 - acc: 0.7589 - val_loss: 0.5384 - val_acc: 0.7505\n","\n","Epoch 00004: val_loss improved from 0.54039 to 0.53842, saving model to avg-concat-los_3-best_model.hdf5\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 360us/step - loss: 0.5020 - acc: 0.7672 - val_loss: 0.5390 - val_acc: 0.7495\n","\n","Epoch 00005: val_loss did not improve from 0.53842\n","Epoch 6/100\n","15219/15219 [==============================] - 5s 358us/step - loss: 0.4985 - acc: 0.7682 - val_loss: 0.5398 - val_acc: 0.7477\n","\n","Epoch 00006: val_loss did not improve from 0.53842\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.4924 - acc: 0.7708 - val_loss: 0.5392 - val_acc: 0.7495\n","\n","Epoch 00007: val_loss did not improve from 0.53842\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 347us/step - loss: 0.4863 - acc: 0.7731 - val_loss: 0.5441 - val_acc: 0.7440\n","\n","Epoch 00008: val_loss did not improve from 0.53842\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 360us/step - loss: 0.4828 - acc: 0.7776 - val_loss: 0.5427 - val_acc: 0.7458\n","\n","Epoch 00009: val_loss did not improve from 0.53842\n","auc-0.7132067117851404, auprc-0.4983142523170855, acc-0.750459981600736, f1-0.364381956649092\n","Problem type:  los_7\n","__________________\n","Inputs-GRU, 256, concat\n","15219\n","Train on 15219 samples, validate on 2164 samples\n","Epoch 1/100\n","15219/15219 [==============================] - 6s 393us/step - loss: 0.2845 - acc: 0.9190 - val_loss: 0.2624 - val_acc: 0.9233\n","\n","Epoch 00001: val_loss improved from inf to 0.26236, saving model to avg-concat-los_7-best_model.hdf5\n","Epoch 2/100\n","15219/15219 [==============================] - 5s 359us/step - loss: 0.2517 - acc: 0.9221 - val_loss: 0.2599 - val_acc: 0.9247\n","\n","Epoch 00002: val_loss improved from 0.26236 to 0.25990, saving model to avg-concat-los_7-best_model.hdf5\n","Epoch 3/100\n","15219/15219 [==============================] - 5s 356us/step - loss: 0.2416 - acc: 0.9221 - val_loss: 0.2615 - val_acc: 0.9247\n","\n","Epoch 00003: val_loss did not improve from 0.25990\n","Epoch 4/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.2361 - acc: 0.9218 - val_loss: 0.2592 - val_acc: 0.9247\n","\n","Epoch 00004: val_loss improved from 0.25990 to 0.25920, saving model to avg-concat-los_7-best_model.hdf5\n","Epoch 5/100\n","15219/15219 [==============================] - 5s 350us/step - loss: 0.2304 - acc: 0.9234 - val_loss: 0.2593 - val_acc: 0.9247\n","\n","Epoch 00005: val_loss did not improve from 0.25920\n","Epoch 6/100\n","15219/15219 [==============================] - 6s 367us/step - loss: 0.2246 - acc: 0.9231 - val_loss: 0.2605 - val_acc: 0.9247\n","\n","Epoch 00006: val_loss did not improve from 0.25920\n","Epoch 7/100\n","15219/15219 [==============================] - 5s 360us/step - loss: 0.2199 - acc: 0.9238 - val_loss: 0.2624 - val_acc: 0.9256\n","\n","Epoch 00007: val_loss did not improve from 0.25920\n","Epoch 8/100\n","15219/15219 [==============================] - 5s 354us/step - loss: 0.2177 - acc: 0.9239 - val_loss: 0.2630 - val_acc: 0.9247\n","\n","Epoch 00008: val_loss did not improve from 0.25920\n","Epoch 9/100\n","15219/15219 [==============================] - 5s 352us/step - loss: 0.2131 - acc: 0.9254 - val_loss: 0.2672 - val_acc: 0.9233\n","\n","Epoch 00009: val_loss did not improve from 0.25920\n","auc-0.7262594008241202, auprc-0.21743148096919157, acc-0.9181232750689973, f1-0.0273224043715847\n"]}],"source":["embedding_types = ['word2vec', 'fasttext', 'concat']\n","embedding_dict = [ner_word2vec, ner_fasttext, ner_concat]\n","target_problems = ['mort_hosp', 'mort_icu', 'los_3', 'los_7']\n","\n","\n","num_epoch = 100\n","model_patience = 5\n","monitor_criteria = 'val_loss'\n","batch_size = 64\n","iter_num = 2\n","unit_sizes = [128, 256]\n","\n","#layers = [\"LSTM\", \"GRU\"]\n","layers = [\"GRU\"]\n","for each_layer in layers:\n","    print (\"Layer: \", each_layer)\n","    for each_unit_size in unit_sizes:\n","        print (\"Hidden unit: \", each_unit_size)\n","\n","        for embed_dict, embed_name in zip(embedding_dict, embedding_types):    \n","            print (\"Embedding: \", embed_name)\n","            print(\"=============================\")\n","\n","            temp_train_ner = dict((k, embed_dict[k]) for k in train_ids)\n","            temp_dev_ner = dict((k, embed_dict[k]) for k in dev_ids)\n","            temp_test_ner = dict((k, embed_dict[k]) for k in test_ids)\n","\n","            x_train_ner = create_dataset(temp_train_ner)\n","            x_dev_ner = create_dataset(temp_dev_ner)\n","            x_test_ner = create_dataset(temp_test_ner)\n","\n","            for iteration in range(1, iter_num):\n","                print (\"Iteration number: \", iteration)\n","\n","                for each_problem in target_problems:\n","                    print (\"Problem type: \", each_problem)\n","                    print (\"__________________\")\n","\n","                    early_stopping_monitor = EarlyStopping(monitor=monitor_criteria, patience=model_patience)\n","                    best_model_name = \"avg-\"+str(embed_name)+\"-\"+str(each_problem)+\"-\"+\"best_model.hdf5\"\n","                    checkpoint = ModelCheckpoint(best_model_name, monitor='val_loss', verbose=1, save_best_only=True, mode='min', period=1)\n","\n","\n","                    callbacks = [early_stopping_monitor, checkpoint]\n","\n","                    model = avg_ner_model(each_layer, each_unit_size, embed_name)\n","                    print(len(x_train_ner))\n","                    model.fit([x_train_lstm, x_train_ner], y_train[each_problem], epochs=num_epoch, verbose=1, \n","                              validation_data=([x_dev_lstm, x_dev_ner], y_dev[each_problem]), callbacks=callbacks, batch_size=batch_size )\n","\n","                    model.load_weights(best_model_name)\n","\n","                    probs, predictions = make_prediction_multi_avg(model, [x_test_lstm, x_test_ner])\n","                    \n","                    save_scores_multi_avg(predictions, probs, y_test[each_problem], \n","                               embed_name, each_problem, iteration, each_unit_size, \n","                               each_layer, type_of_ner)\n","                    \n","                    reset_keras(model)\n","                    # del model\n","                    clear_session()\n","                    gc.collect()"]},{"cell_type":"code","source":["df = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/CS598_DLH_Paper211/results/proposed/GRU-256-word2vec-los_3-1-new-avg-.p')\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ASE8iVeH7U3b","executionInfo":{"status":"ok","timestamp":1650737713446,"user_tz":300,"elapsed":345,"user":{"displayName":"Prash S","userId":"14515616873443422507"}},"outputId":"11ba8d37-157b-4960-ac7c-46f3a8abde36"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'F1': 0.39043381535038935,\n"," 'acc': 0.7479300827966882,\n"," 'auc': 0.7174508392137696,\n"," 'auprc': 0.5021809956612135}"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["df = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/CS598_DLH_Paper211/results/proposed/GRU-256-word2vec-los_7-1-new-avg-.p')\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SHGRqRZ87dmu","executionInfo":{"status":"ok","timestamp":1650737714843,"user_tz":300,"elapsed":214,"user":{"displayName":"Prash S","userId":"14515616873443422507"}},"outputId":"82e27237-6209-4ac8-bdb2-132d7001dab5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'F1': 0.022038567493112945,\n"," 'acc': 0.9183532658693653,\n"," 'auc': 0.7249850825245998,\n"," 'auprc': 0.21163941744228756}"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["df = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/CS598_DLH_Paper211/results/proposed/GRU-256-word2vec-mort_hosp-1-new-avg-.p')\n","df"],"metadata":{"id":"D8pp-k6G8Y6O","executionInfo":{"status":"ok","timestamp":1650737717307,"user_tz":300,"elapsed":199,"user":{"displayName":"Prash S","userId":"14515616873443422507"}},"outputId":"d844be65-9154-4818-cfd9-02a25dc86e31","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'F1': 0.4523076923076923,\n"," 'acc': 0.9181232750689973,\n"," 'auc': 0.8793478500308397,\n"," 'auprc': 0.5881763419305859}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["df = pd.read_pickle('/content/drive/MyDrive/Colab Notebooks/CS598_DLH_Paper211/results/proposed/GRU-256-word2vec-mort_icu-1-new-avg-.p')\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iuTLW99T7ocF","executionInfo":{"status":"ok","timestamp":1650737718554,"user_tz":300,"elapsed":319,"user":{"displayName":"Prash S","userId":"14515616873443422507"}},"outputId":"7cccba83-b937-4770-9425-d058d0d94056"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'F1': 0.48648648648648646,\n"," 'acc': 0.9431922723091076,\n"," 'auc': 0.8869633409803829,\n"," 'auprc': 0.5319617559182519}"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":[""],"metadata":{"id":"cx4jPXw98es3"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"name":"08-Multimodal-Baseline.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}